<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>How Smart Machines Think: The DARPA Grand Challenge</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="articlestyle.css">
  <link href="https://fonts.googleapis.com/css?family=Muli%7CRoboto:400,300,500,700,900" rel="stylesheet"></head>
  <body>

    <div class="main-nav">
        <ul class="nav">
          <li class="name">Zuber Najam</li>
          <li><a href="index.html">Home</a></li>
          <li><a href="about.html">About</a></li>
          <li><a href="portfolio.html">Portfolio</a></li>
          <li><a href="blog.html">Blog</a></li>
          <li><a href="contact.html">Contact</a></li>
        </ul>
    </div>
    <div class="article">
      <article>
        <header>
          <h1>A Review of <em>How Smart Machines Think</em> by Sean Gerrish (The DARPA Challenge)</h1>
          <p>By: Zuber Najam </p>
          <p id="date">February 17, 2020</p>
        </header>
        
        <p>One of the most exciting things about reading a piece of non-fiction is discovering something new and exciting about a topic that is important to you. Being a student of computer science, what I find fascinating are the real-life applications of computer science principles. It is for this reason that I am excited to write a series of blogposts summarizing the various smart machines discussed in Sean Gerrish’s book, <em>How Smart Machines Think</em>.</p>
        <p>In his book, Gerrish does a great job of introducing the reader to several different automatons, or self-moving machines, of the early 20th century. The first of these automatons introduced, and the ones that I will address in this blog post are the smart cars that raced across the Mojave Desert in The DARPA Grand Challenge.</p>

        <h3>The DARPA Grand Challenge</h3>
        <figure>
          <img src="images3/CMU_Sandstorm.jpeg" alt="CMU's Sandstorm vehicle" width="400" height="300"/>
        <br />
        <figcaption> The Red Team's self driving vehicle "Sandstorm". <a href="https://en.wikipedia.org/wiki/Sandstorm_(vehicle)#/media/File:CMU_Sandstorm.jpg">Image Source</a> </figcaption>
        </figure>

        <p>The first DARPA Grand Challenge took place in the Mojave Desert in 2004. It was organized by a branch of the US Defense Department known as the Defense Advanced Research Projects Agency. It was a 142-mile race with a $1 million prize waiting at the finish line. Several interesting self-driving vehicles entered the race. The most promising vehicle was designed by Chris Urmson from Carnegie Mellon University (CMU) under the guidance of legendary roboticist William Whittaker. The CMU team, also called The Red Team, developed a self-driving Humvee for the competition. Its design consisted of a modular approach. The speed was controlled by a centrifugal governor which created a feedback loop which closed a valve over the fuel line to slow down the car and increased the fuel supply to the engine to increase the speed of the car. This self-driving vehicle only had one speed that it could go. For the purpose of this race, that was good enough. The most important part of the car was the planning component. This incorporated algorithms that assigned different values to the different parts of the track. Terrain that was rough and or dangerous were given higher scores or penalties and the safe terrain was assigned lower scores. The planning component would take this information, process it, and then provide instruction prompting the self-driving car to pursue a path through safer terrain. The third component of the smart design was the navigation system. It consisted of a GPS sensor strapped onto the car which triangulated the current time and the position of the car and accelerometers to measure acceleration in three-dimensional space. The measurements from the GPS and the accelerometers were combined using a Kalman filter and were used to approximate an objects position and velocity. The last component added to the Humvee was an “eye”. It was a combination of a laser and light sensor, aka lidar, which would allow the vehicle to see fences, boulders, etc. This “eye” was very rudimentary, and it would ultimately prove to be a liability. The Humvee traveled well for about 7 miles in the race. Then it made a sharp turn and ran into the rock where it got stuck. The vehicle spun its wheels for seven minutes until they caught on fire. At this point, nearby officials hit the e-kill switch and ended the race for the Humvee. When the race officially came to an end, not a single self-driving vehicle had crossed the finish line to claim the $1 million at the end. However, neither the teams that took part in the race nor the DARPA organizers could call the event a failure. In fact, the advancement in the field of self-driving calls had made greater advancements over the months leading up to the competition than they had over the past 8 years. Despite initial failure, another opportunity would arise in little over a year when the second Grand Challenge was to be held with a grand prize of $2 million.</p>

        <h3>The Second DARPA Grand Challenge</h3>
        <figure>
          <img src="images3/Stanley.jpeg" alt="Stanford’s self-driving vehicle 'Stanley'". width="400" height="300"/>
        <br />
        <figcaption> Stanford’s self-driving vehicle 'Stanley'. <a href="https://en.wikipedia.org/wiki/Stanley_(vehicle)#/media/File:Stanley2.JPG">Image Source</a> </figcaption>
        </figure>
        <p> The Red Team took to heart the lessons learned from their initial failure. Their strategy the second go around was to focus primarily on mapping and navigation. Over the course of a month, they had three drivers scan 2,000 miles of the Mojave Desert to determine possible routes that the self-driving car might take. Additionally, they implemented a rule to ensure that a finish like the one they had witnessed in the first Grand Challenge didn’t repeat itself. The Humvee was programmed such that if it got stuck, meaning that if the wheels were turning but its GPS sensor did not sense that it was getting anywhere, it would backup 10 meters, clear the obstacle, and try to progress forward again. These modifications worked and The Red Team’s vehicle finished the race of 132 miles. However, The Red Team did not win the race. A dark horse of a vehicle, built by the Stanford Racing Team and named Stanley, would cross the finish line over 10 minutes before The Red Team’s Humvee.</p> 
        <p>The Stanford Racing Team was led by the head of Stanford’s artificial intelligence laboratory Sebastian Thrun. The team was able to perform so well in the race because they understood early on that putting emphasis on mapping and navigation while compromising the self-driving cars ability to sense the environment that it was driving in was a mistake. Instead, the Stanford Racing Team approached the design philosophy that autonomous navigation should be treated as a software problem. To address this problem, the team turned to machine learning. Although it was not unheard of, machine learning was hardly the preferred choice for designing a self-driving car at the time. The Stanford Racing Team knew that they had their work cut out for them. They understood that for Stanley to compete in the race, they needed to design a way for Stanley to both perceive and react to the world in real-time.</p>
        <p>To accomplish these goals, the team decided on an architecture that brought three separate layers together. The leftmost part of the architecture was known as the hardware layer and it consisted of sensors to collect the raw data and actuators to control steering, speed, and braking. Nothing about this layer was “smart” in and of itself. On the rightmost side was the thinking layer which performed the high-level planning for the vehicle. Basically, this was the “smart” layer that made the decisions on how the car should drive. It communicated this information to the leftmost layer. In between the leftmost and the rightmost layer was the middle layer. The middle layer was tasked with taking the raw data from the leftmost side and converting that into interoperable models that the rightmost layer could use to make decisions.</p>
        <p>Several machine learning modules were running in the middle layer to guide the vehicles ability to generate reliable models. To help Stanley navigate the terrain, it was programmed to visualize itself on a grid. It had been outfitted with scanners to collect data which was processed to determine which cells on the grid were “occupied” and which ones were not. The planning algorithms would allow Stanley to safely travel over the non-occupied cells while swerving away from the occupied cells. In theory, this approach was perfect. However, it had some flaws that needed to be addressed. For example, if the scanners tilted just a fraction of a degree, the unoccupied cells in front of Stanley might be labeled as occupied, causing Stanley to swerve off the road. Sebastian understood that they needed to implement algorithms that could make sense of the data coming in more accurately. Sebastian realized that this was the perfect opportunity to use machine learning algorithms to teach Stanley how to make sense of the different data that it would collect while navigating the terrain. Sebastian had someone drive Stanley around while the scanners collected the data. Since the driver would only drive Stanley on terrain that was safe, the data collected would be used to fine tune the obstacle-detection model that was being used. In terms of machine learning, the algorithms would be <em>trained</em> on the data collected by the sensors in a method known as <em>supervised classification</em>.</p>
        <p> Now that the issue of driving on safe terrain had been resolved, there was still another matter that required Sebastian’s attention. In order to finish the race as quickly as possible, Stanly would need to stay on the road. As it stood, Stanley would gladly veer off the road, if the surrounding terrain was “safe”. In order to keep Stanley traveling inside the road’s edges, additional laser scanners were added which would scan for the road’s edges. The road-edge-detecting module would then check to see outermost distance/line without a detected obstacle. This would set the road boundary within which Stanley was to travel. Now, Stanley could drive within the road for the duration of the race. The only thing left now was to make sure that Stanley could drive fast enough to win the race.</p>
        <p>The laser scanners that Stanley was equipped with would allow it to see about 30 meters ahead of it. With such a limited vision, it was not safe to drive any faster than 25 miles per hour. For Stanley to drive safely at a higher speed, Sebastian and the team decided to attach a color camera to the front of the vehicle. This allowed Stanley to see a greater distance ahead so that the vehicle could determine if the road stretched out far ahead. If so, then Stanley could safely increase his speed to 45 miles per hour. Now, this was easier said than done. Unlike us humans, a smart vehicle cannot automatically discriminate between the road, the sky, or a ditch. A machine learning technique called “clustering” was utilized to group similar colors of pixels together. Since the color of pixels that make up the road are different that the color of pixels that make up the sky and the side of the roads, Stanley was able to learn where to drive by following the pixels. Now Stanley was capable of being competitive.</p>
        <p>There were a lot of modules that worked together to make sure that Stanley was able to successfully complete the race. With so many different modules and algorithms working simultaneously, one would think that the possibility of something going wrong would be high. However, because there were so many different modules and algorithms working in unison, the faltering of one module would not be catastrophic since another module would be there to keep the vehicle driving on the road. For example, if the image from the color camera was misinterpreted and Stanley started to drive of the road, the laser scanners would make sure that the vehicle stayed within the edges of the road long enough for another picture of the road to be taken and interpreted. Because of this emphasis on machine learning, Sebastian and his team won the second DARPA challenge, beating out the CMU team by a span of 10 minutes. </p>
        <p>When DARPA announced their next competition, the DARPA Urban Challenge, Chris Urmson’s team, aka the Red Team, knew that they had been given one more shot to win first place. In order to do so, they would need to learn from the first two DARPA competitions. The DARPA Urban Challenge would require the autonomous vehicles to obey California traffic laws. For the Red Team to win this challenge, they would need to build a car that could do far more than Stanley did in the second DARPA Grand Challenge.</p>




      
        <h3>The DARPA Urban Challenge</h3>
        <figure>
          <img src="images3/Boss.jpeg" alt="CMU's self-driving vehicle 'Boss'". width="400" height="300"/>
        <br />
        <figcaption> CMU’s self-driving vehicle 'Boss'. <a href="https://www.cmu.edu/news/image-archive/Boss.jpg.">Image Source</a> </figcaption>
        </figure>
        <p> The third DARPA challenge would see self-driving automobiles on the same circuit as human drivers. For this race, Urmson’s team retired their Humvee and choose to go forward with a 2007 Chevrolet Tahoe named “Boss”. In order to ensure that Boss could compete in this challenge, Boss’ architecture was designed with three layers like the architecture of Stanley from the previous race.  By design, the modules increased in their level of reasoning abstraction moving from left to right. The leftmost module was the hardware layer. It consisted of modules for sensing (lidars, camera, GPS, accelerometers, and gyros) and actuator modules (steering, breaking, and speed). The middle layer was the Perception and world modeling layer. As the name of the layer implies, it was divided into the perception modules (moving object detection, obstacle detection, and road edge detection) and world model modules (static and moving obstacles, road map, and position and speed of car). In a nutshell, this layer took the role of synthesizing the data that came in from the 18 sensors that Boss had. The rightmost and the highest-level reasoning layer was the planning layer. This layer was divided into its own three-layer architecture consisting of the controller (route planner module), the sequencer (monopoly board module), and the deliberator (motion planner module). </p>
        <p>The setup of the urban race was much more sophisticated and demanding than either of the previous races. The self-driving cars participating in the race would need to complete a series of “missions”. They would need to drive from one checkpoint to another while obeying California traffic laws and navigating through traffic. The map of the circuit had been provided to the teams a couple of days prior to the race but the mission descriptions had been kept secret until the final moments leading up to the race. The missions included tasks such as parking into a lot and navigating through intersections. The cars that were permitted to take part in this race had been carefully vetted. Before the morning was over, half of the automobiles had already been removed from the circuit. However, there were still several cars, including Boss that successfully completed the race. Looking back at the race. It is truly amazing how far self-driving cars had come over such a short length of time. It would have been impossible for either Sandstorm or Stanley to qualify much less finish the urban challenge. Due to some significant advances in the software architecture of Boss, it was able to do everything asked of it in the Urban Challenge.</p>
        <p>The reasoning architecture that was mentioned earlier deserves the credit for Boss’ success in the urban challenge. Organizing the design into three layers allowed the hardware layer to collect all the required data from the sensors so that the other layers were not burdened by it. The perception layer in turn focused entirely on using machine learning modules to make sense of the incoming data and converting it into actionable information. Lastly, the planning layer was singly responsible for the high-level thinking and the decision making for the vehicle. As previously mentioned, the planning layers sub-architecture consisted of the controller (the route planning module), the sequencer (Monopoly board module), and the deliberator (motion planner module). The controller set the route the vehicle should take, and it continuously updated the route considering new information. The Monopoly board was a finite state machine which allowed Boss to make decisions based on its current position and which position it needs to be in next. The motion planner was responsible for determine the trajectory Boss needed to make in order to safely get from its current position to the necessary next position. Together, these three modules within the planning layer allowed for successful navigation throughout the Urban Challenge. Granted, the software architecture was by no means bug free. Self-driving cars are very complex and require a whole lot of software to be written. By implementing a tested error-recovery system, Urmson’s team insured that Boss was able to work its way through jams of both the technical and the traffic kind.</p>
        <p> The DARPA challenges did wonders for the field of self-driving cars. Looking back at them from the year 2020, the vehicles that raced across the Mojave Desert certainly do seem primitive. Today, multiple companies, including Uber and Alphabet are testing self-driving vehicles on the same roads that we ourselves travel. There is still a lot of work that needs to be done in this field and for all intents and purposes, the self-driving vehicle industry is still in its infancy. Only time will tell what impact self-driving vehicles have on our society.</p> 

        <hr>
        <h3>Notes</h3>
        <p>1. Gerrish, Sean. How Smart Machines Think. The MIT Press, 2019.</p>
      </article>
    </div>
  </body>